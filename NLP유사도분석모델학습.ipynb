{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3893aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers datasets\n",
    "# !pip install scikit-learn\n",
    "# !pip install --upgrade pip\n",
    "# !pip install SpeechRecognition\n",
    "# !pip install pyautogui\n",
    "# !pip install clipboard\n",
    "# !pip install keyboard\n",
    "# !pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa3c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer,  LoggingHandler, losses, models, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d3537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[LoggingHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f5bf400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"klue/roberta-base\"\n",
    "\n",
    "train_batch_size = 32\n",
    "num_epochs = 1\n",
    "model_save_path = \"output/training_klue_sts_\" + model_name.replace(\"/\", \"-\") + \"-\" + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3689e9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = models.Transformer(model_name)\n",
    "\n",
    "pooler = models.Pooling(\n",
    "    embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97789a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 16:00:32 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(modules=[embedding_model, pooler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe922437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 16:00:36 - Found cached dataset klue (C:/Users/maili/.cache/huggingface/datasets/klue/sts/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcc91d36c394dab96c7ae0b98094780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 16:00:40 - Found cached dataset kor_nlu (C:/Users/maili/.cache/huggingface/datasets/kor_nlu/sts/1.0.0/4facbba77df60b0658056ced2052633e681a50187b9428bd5752ebd59d332ba8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322e1331e01b48a9aebd9f9721d4b164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset(\"klue\", \"sts\")\n",
    "testsets = load_dataset(\"kor_nlu\", \"sts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350d0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "# KLUE STS 내 훈련, 검증 데이터 예제 변환\n",
    "for phase in [\"train\", \"validation\"]:\n",
    "    examples = datasets[phase]\n",
    "\n",
    "    for example in examples:\n",
    "        score = float(example[\"labels\"][\"label\"]) / 5.0  # 0.0 ~ 1.0 스케일로 유사도 정규화\n",
    "\n",
    "        inp_example = InputExample(\n",
    "            texts=[example[\"sentence1\"], example[\"sentence2\"]], \n",
    "            label=score,\n",
    "        )\n",
    "\n",
    "        if phase == \"validation\":\n",
    "            dev_samples.append(inp_example)\n",
    "        else:\n",
    "            train_samples.append(inp_example)\n",
    "\n",
    "# KorSTS 내 테스트 데이터 예제 변환\n",
    "for example in testsets[\"test\"]:\n",
    "    score = float(example[\"score\"]) / 5.0\n",
    "\n",
    "    if example[\"sentence1\"] and example[\"sentence2\"]:\n",
    "        inp_example = InputExample(\n",
    "            texts=[example[\"sentence1\"], example[\"sentence2\"]],\n",
    "            label=score,\n",
    "        )\n",
    "\n",
    "    test_samples.append(inp_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38786c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[0].texts, train_samples[0].label\n",
    "test_samples[0].texts, test_samples[0].label\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_samples,\n",
    "    shuffle=True,\n",
    "    batch_size=train_batch_size,\n",
    ")\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c36335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    dev_samples,\n",
    "    name=\"sts-dev\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "305477fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 16:00:41 - Warmup-steps: 37\n"
     ]
    }
   ],
   "source": [
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs  * 0.1)  # 10% of train data for warm-up\n",
    "logging.info(f\"Warmup-steps: {warmup_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7ecfc",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1057f123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee47794fc12d4a79b772159bc1b07818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31356370fd2c4a0ab7ee063b7c890ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 16:02:12 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 0:\n",
      "2022-12-22 16:02:13 - Cosine-Similarity :\tPearson: 0.8649\tSpearman: 0.8618\n",
      "2022-12-22 16:02:13 - Manhattan-Distance:\tPearson: 0.8669\tSpearman: 0.8602\n",
      "2022-12-22 16:02:13 - Euclidean-Distance:\tPearson: 0.8672\tSpearman: 0.8602\n",
      "2022-12-22 16:02:13 - Dot-Product-Similarity:\tPearson: 0.8555\tSpearman: 0.8483\n",
      "2022-12-22 16:02:13 - Save model to output/training_klue_sts_klue-roberta-base-2022-12-22_16-00-28\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=1000,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=model_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6d684dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 16:02:35 - Load pretrained SentenceTransformer: output/training_klue_sts_klue-roberta-base-2022-12-22_16-00-28\n",
      "2022-12-22 16:02:35 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5734d903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 16:02:35 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:02:38 - Cosine-Similarity :\tPearson: 0.7642\tSpearman: 0.7526\n",
      "2022-12-22 16:02:38 - Manhattan-Distance:\tPearson: 0.7632\tSpearman: 0.7576\n",
      "2022-12-22 16:02:38 - Euclidean-Distance:\tPearson: 0.7629\tSpearman: 0.7572\n",
      "2022-12-22 16:02:38 - Dot-Product-Similarity:\tPearson: 0.7439\tSpearman: 0.7300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7575724107071362"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72489820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486b11bc1a9d4af5b245bcb1d4d204d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = [\n",
    "         \"친구가 갑자기 다리밑에서 배가 아파요\",\n",
    "        \"동료가 길을 가다가 쓰러졌습니다\"\n",
    "]\n",
    "document_embeddings = model.encode(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e328ee73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e457e710835f4906bf77d00cc6c3f782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"친구가 갑자기 다리밑에서 쓰러졌습니다\"\n",
    "query_embedding = model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d098d056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 친구가 갑자기 다리밑에서 쓰러졌습니다\n",
      "\n",
      "<입력 문장과 유사한 2 개의 문장>\n",
      "\n",
      "1: 친구가 갑자기 다리밑에서 배가 아파요 (유사도: 0.7487)\n",
      "\n",
      "2: 동료가 길을 가다가 쓰러졌습니다 (유사도: 0.5807)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_k = min(5, len(docs))\n",
    "\n",
    "# 입력 문장 - 문장 후보군 간 코사인 유사도 계산 후,\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, document_embeddings)[0]\n",
    "\n",
    "# 코사인 유사도 순으로 `top_k` 개 문장 추출\n",
    "top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "print(f\"입력 문장: {query}\")\n",
    "print(f\"\\n<입력 문장과 유사한 {top_k} 개의 문장>\\n\")\n",
    "\n",
    "for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "    print(f\"{i+1}: {docs[idx]} {'(유사도: {:.4f})'.format(score)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d731bf",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb7be72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 16:02:38 - Load pretrained SentenceTransformer: training_klue_sts_klue-roberta-base-2022-12-18_19-36-15\n",
      "2022-12-22 16:02:39 - Use pytorch device: cuda\n",
      "2022-12-22 16:02:39 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:02:41 - Cosine-Similarity :\tPearson: 0.7590\tSpearman: 0.7489\n",
      "2022-12-22 16:02:41 - Manhattan-Distance:\tPearson: 0.7568\tSpearman: 0.7541\n",
      "2022-12-22 16:02:41 - Euclidean-Distance:\tPearson: 0.7564\tSpearman: 0.7537\n",
      "2022-12-22 16:02:41 - Dot-Product-Similarity:\tPearson: 0.7375\tSpearman: 0.7273\n",
      "2022-12-22 16:02:41 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:02:43 - Cosine-Similarity :\tPearson: 0.7590\tSpearman: 0.7489\n",
      "2022-12-22 16:02:43 - Manhattan-Distance:\tPearson: 0.7568\tSpearman: 0.7541\n",
      "2022-12-22 16:02:43 - Euclidean-Distance:\tPearson: 0.7564\tSpearman: 0.7537\n",
      "2022-12-22 16:02:43 - Dot-Product-Similarity:\tPearson: 0.7375\tSpearman: 0.7273\n",
      "0.7540743241026938\n",
      "2022-12-22 16:02:43 - Load pretrained SentenceTransformer: training_klue_sts_klue-roberta-base-2022-12-18_19-51-30\n",
      "2022-12-22 16:02:44 - Use pytorch device: cuda\n",
      "2022-12-22 16:02:44 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:02:46 - Cosine-Similarity :\tPearson: 0.7700\tSpearman: 0.7626\n",
      "2022-12-22 16:02:46 - Manhattan-Distance:\tPearson: 0.7639\tSpearman: 0.7648\n",
      "2022-12-22 16:02:46 - Euclidean-Distance:\tPearson: 0.7644\tSpearman: 0.7652\n",
      "2022-12-22 16:02:46 - Dot-Product-Similarity:\tPearson: 0.7341\tSpearman: 0.7224\n",
      "2022-12-22 16:02:46 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:02:48 - Cosine-Similarity :\tPearson: 0.7700\tSpearman: 0.7626\n",
      "2022-12-22 16:02:48 - Manhattan-Distance:\tPearson: 0.7639\tSpearman: 0.7648\n",
      "2022-12-22 16:02:48 - Euclidean-Distance:\tPearson: 0.7644\tSpearman: 0.7652\n",
      "2022-12-22 16:02:48 - Dot-Product-Similarity:\tPearson: 0.7341\tSpearman: 0.7224\n",
      "0.7652471597286736\n",
      "2022-12-22 16:02:48 - Load pretrained SentenceTransformer: training_klue_sts_klue-roberta-base-2022-12-18_22-46-00\n",
      "2022-12-22 16:02:49 - Use pytorch device: cuda\n",
      "2022-12-22 16:02:49 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:02:51 - Cosine-Similarity :\tPearson: 0.7538\tSpearman: 0.7453\n",
      "2022-12-22 16:02:51 - Manhattan-Distance:\tPearson: 0.7478\tSpearman: 0.7462\n",
      "2022-12-22 16:02:51 - Euclidean-Distance:\tPearson: 0.7476\tSpearman: 0.7459\n",
      "2022-12-22 16:02:51 - Dot-Product-Similarity:\tPearson: 0.7078\tSpearman: 0.6922\n",
      "2022-12-22 16:02:51 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:02:53 - Cosine-Similarity :\tPearson: 0.7538\tSpearman: 0.7453\n",
      "2022-12-22 16:02:53 - Manhattan-Distance:\tPearson: 0.7478\tSpearman: 0.7462\n",
      "2022-12-22 16:02:53 - Euclidean-Distance:\tPearson: 0.7476\tSpearman: 0.7459\n",
      "2022-12-22 16:02:53 - Dot-Product-Similarity:\tPearson: 0.7078\tSpearman: 0.6922\n",
      "0.7462486496313626\n",
      "2022-12-22 16:02:53 - Load pretrained SentenceTransformer: training_klue_sts_klue-roberta-base-2022-12-19_04-33-15\n",
      "2022-12-22 16:02:54 - Use pytorch device: cuda\n",
      "2022-12-22 16:02:54 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:02:56 - Cosine-Similarity :\tPearson: 0.7715\tSpearman: 0.7616\n",
      "2022-12-22 16:02:56 - Manhattan-Distance:\tPearson: 0.7691\tSpearman: 0.7671\n",
      "2022-12-22 16:02:56 - Euclidean-Distance:\tPearson: 0.7690\tSpearman: 0.7670\n",
      "2022-12-22 16:02:56 - Dot-Product-Similarity:\tPearson: 0.7392\tSpearman: 0.7263\n",
      "2022-12-22 16:02:56 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:02:58 - Cosine-Similarity :\tPearson: 0.7715\tSpearman: 0.7616\n",
      "2022-12-22 16:02:58 - Manhattan-Distance:\tPearson: 0.7691\tSpearman: 0.7671\n",
      "2022-12-22 16:02:58 - Euclidean-Distance:\tPearson: 0.7690\tSpearman: 0.7670\n",
      "2022-12-22 16:02:58 - Dot-Product-Similarity:\tPearson: 0.7392\tSpearman: 0.7263\n",
      "0.7670928479133706\n"
     ]
    }
   ],
   "source": [
    "def model(model):\n",
    "    model_save_path = model\n",
    "    model = SentenceTransformer(model_save_path)\n",
    "    test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "    test_evaluator(model, output_path=model_save_path)\n",
    "    print(test_evaluator(model, output_path=model_save_path))\n",
    "    \n",
    "ModelList =  [\"training_klue_sts_klue-roberta-base-2022-12-18_19-36-15\" , # 1번\n",
    "              \"training_klue_sts_klue-roberta-base-2022-12-18_19-51-30\" , # 100번\n",
    "              \"training_klue_sts_klue-roberta-base-2022-12-18_22-46-00\" , # 200번\n",
    "              \"training_klue_sts_klue-roberta-base-2022-12-19_04-33-15\"   # 300번\n",
    "             ]   \n",
    "\n",
    "for i in range(len(ModelList)):\n",
    "    model(ModelList[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff401b3c",
   "metadata": {},
   "source": [
    "# 크게 차이는 없지만 모델 중 그나마 300번 정도 학습한 모델이 가장 정확도가 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d908758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 16:02:58 - Load pretrained SentenceTransformer: training_klue_sts_klue-roberta-base-2022-12-19_04-33-15\n",
      "2022-12-22 16:02:59 - Use pytorch device: cuda\n",
      "2022-12-22 16:02:59 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:03:01 - Cosine-Similarity :\tPearson: 0.7715\tSpearman: 0.7616\n",
      "2022-12-22 16:03:01 - Manhattan-Distance:\tPearson: 0.7691\tSpearman: 0.7671\n",
      "2022-12-22 16:03:01 - Euclidean-Distance:\tPearson: 0.7690\tSpearman: 0.7670\n",
      "2022-12-22 16:03:01 - Dot-Product-Similarity:\tPearson: 0.7392\tSpearman: 0.7263\n",
      "2022-12-22 16:03:01 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2022-12-22 16:03:03 - Cosine-Similarity :\tPearson: 0.7715\tSpearman: 0.7616\n",
      "2022-12-22 16:03:03 - Manhattan-Distance:\tPearson: 0.7691\tSpearman: 0.7671\n",
      "2022-12-22 16:03:03 - Euclidean-Distance:\tPearson: 0.7690\tSpearman: 0.7670\n",
      "2022-12-22 16:03:03 - Dot-Product-Similarity:\tPearson: 0.7392\tSpearman: 0.7263\n",
      "0.7670928479133706\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222a6e78e3e5415abedc294333fe8568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474a6d097d134935bf30b522119b7004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 친구가 갑자기 다리밑에서 쓰러졌습니다\n",
      "\n",
      "<입력 문장과 유사한 2 개의 문장>\n",
      "\n",
      "1: 친구가 갑자기 다리밑에서 배가 아파요 (유사도: 0.7658)\n",
      "\n",
      "2: 동료가 길을 가다가 쓰러졌습니다 (유사도: 0.5795)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"training_klue_sts_klue-roberta-base-2022-12-19_04-33-15\"\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)\n",
    "print(test_evaluator(model, output_path=model_save_path))\n",
    "\n",
    "docs = [\n",
    "        \"친구가 갑자기 다리밑에서 배가 아파요\",\n",
    "        \"동료가 길을 가다가 쓰러졌습니다\"\n",
    "]\n",
    "document_embeddings = model.encode(docs)\n",
    "\n",
    "query = \"친구가 갑자기 다리밑에서 쓰러졌습니다\"\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "\n",
    "top_k = min(5, len(docs))\n",
    "\n",
    "# 입력 문장 - 문장 후보군 간 코사인 유사도 계산 후,\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, document_embeddings)[0]\n",
    "\n",
    "# 코사인 유사도 순으로 `top_k` 개 문장 추출\n",
    "top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "print(f\"입력 문장: {query}\")\n",
    "print(f\"\\n<입력 문장과 유사한 {top_k} 개의 문장>\\n\")\n",
    "\n",
    "for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "    if score > 0.2:\n",
    "        print(f\"{i+1}: {docs[idx]} {'(유사도: {:.4f})'.format(score)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
